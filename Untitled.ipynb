{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My project is about backpropagation algorithm applied to a Neural Network with only one hidden layer. <br>\n",
    "The optimization algorithm I used is Gradient Descent. <br>\n",
    "The dataset I choose is a non linear artificial dataset with a flower shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backpropagation for a NN is an algorithm for computing the gradient of $\\frac{\\partial C}{\\partial w}$ and $\\frac{\\partial C}{\\partial b}$.\n",
    "To compute those, we need to compute a quantity I called $dz$, which is basically the **error** that each neuron of the network introduces.\n",
    "\n",
    "\n",
    "Backpropagation is based around **four** fundamental equations and these equations give us a way of computing both the error that each neuron introduces and the gradient of the cost function wrt weights and biases.\n",
    "\n",
    "- the equation for the **error in the output layer** $dz^{l}$ is given by:\n",
    "    $$dz^{L} = \\frac{\\partial C}{\\partial a^{L}} * \\sigma'(z^{L})$$\n",
    "    Since I used the cross entropy cost function, through some calculations it can be shown that we can compute this error as:\n",
    "    $$dz^{L} = a^{L} - Y$$\n",
    "<br>\n",
    "\n",
    "\n",
    "- the equation for the rate of change of the cost with respect to any **weight** in the network is given by:\n",
    "    $$\\frac{\\partial C}{\\partial w^{l}} = dz^{l} a^{l-1}$$\n",
    "<br>\n",
    "\n",
    "\n",
    "- the equation for the rate of change of the cost with respect to any **bias** in the network is given by:\n",
    "    $$\\frac{\\partial C}{\\partial b^{l}} = dz^{l}$$\n",
    "<br>\n",
    "\n",
    "\n",
    "- the equation for **the error $dz^{l}$ in terms of the error in the next layer** $dz^{l+1}$ is given by:\n",
    "    $$dz^{l} = ((w^{l+1})^T dz^{l+1}) * \\sigma'(z^{l})$$\n",
    "    Since the activation function for the hidden layer is the **tanh** activation function, then $\\sigma'(z^{l}) = 1-a^{{[l]}^{2}}$.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "$$J = - \\frac{1}{m} \\sum\\limits_{i = 1}^{m} \\large{(} \\small y^{(i)}\\log\\left(a^{[2] (i)}\\right) + (1-y^{(i)})\\log\\left(1- a^{[2] (i)}\\right) \\large{)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "An **optimization problem** consists of minimizing (maximizing) a real function by finding the *best available* values from within an allowed set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum and minimum\n",
    "\n",
    "\n",
    "The value of x for which the first derivative f ’(x) is 0 corresponds to a maximum or a minimum of f(x).\n",
    "\n",
    "• For a **maximum** the second derivative f’’(x) is **negative**.\n",
    "\n",
    "• For a **minimum** the second derivative f’’(x) is **positive**.\n",
    "\n",
    "• The second derivative is 0 for an **inflexion point**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonlinear Programming\n",
    "\n",
    "When the objective function and/or the constraints can be nonlinear.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's method\n",
    "\n",
    "**Basic formulation**\n",
    "\n",
    "Newton's method finds the roots (zeros) of a function using **linear approximations** of the function.\n",
    "\n",
    "It tries to guess a solution $x_0$ of the equation f(x) = 0.\n",
    "Then, computes the linear approximation (tangent line) of f(x) at $x_0$ and then finds the x-intercept (y=0) of the linear approximation.\n",
    "\n",
    "<img src=\"img/newton.png\">\n",
    "\n",
    "\n",
    "**Newton's method for Optmization**\n",
    "\n",
    "In **optimization**, our goal is to find optima points (minima, maxima). These points are points where the derivative is null. <br>\n",
    "So we look for the **roots of the derivative** (where the derivative is zero, so f'(x) = 0).\n",
    "\n",
    "The roots are known as stationary points of f. <br>\n",
    "These solutions may be minima, maxima, or saddle (inflection) points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "GD is an iterative algorithm for finding the minimum of a differentiable function.\n",
    "\n",
    "To find a local minimum, it starts from a point x0 and takes steps proportional to the negative of the gradient of the function at the current point.\n",
    "\n",
    "\n",
    "The length of the steps is dictated by a parameter, the **learning rate**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "\n",
    "In Stochastic Gradient Descent (SGD), only a few samples (a “batch”) are randomly selected at each iteration since GD could be computationally very expensive.\n",
    "\n",
    "\n",
    "Pure Stochastic Gradient Descent uses only a single sample, i.e., a batch size of one, to perform each iteration: many iterations very cheap.\n",
    "\n",
    "\n",
    "**Here is why we are saving time**\n",
    "\n",
    "Suppose we have 1 billion data points.\n",
    "\n",
    "In GD, in order to update the parameters once, we need to have the (exact) gradient. This requires to sum up these 1 billion data points to perform 1 update.\n",
    "\n",
    "In SGD, we can think of it as **trying to get an approximated gradient** instead of exact gradient. The approximation is coming from one data point (or several data points called mini batch). Therefore, in SGD, we can update the parameters very quickly. In addition, if we \"loop\" over all data (called one epoch), we actually have 1 billion updates.\n",
    "\n",
    "The trick is that, in SGD you **do not need to have 1 billion iterations/updates, but much less iterations/updates**, say 1 million, and you will have \"good enough\" model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n",
    "\n",
    "Support Vector Machines is machine learning classifier which, given labeled training data, computes an optimal hyperplane which categorize new examples. <br>\n",
    "The optimal hyperplane is the one that maximizes its margin, i.e., the distance between itself and the nearest point to classify.\n",
    "\n",
    "The **support vectors** are the points closest to the separation hyperplane; if all other points were removed and learning re-run the result would be exactly the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear programming\n",
    "When both objective function and constraints are linear function, optimization is named linear programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/formulation.png\" height=\"60%\" width=\"60%\">\n",
    "\n",
    "The geometric view is a **polyhedron** in n-dimensional space. An **optimal solution is at a vertex**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplex Algorithm\n",
    "\n",
    "1.Find a corner of the feasible region\n",
    "\n",
    "2.Repeat <br>\n",
    "        2.1 For each of the n hyperplanes intersecting at the corner, calculate its reduced cost <br>\n",
    "        2.2 If they are all non-negative, then STOP else, pick the most negative reduced cost <br>\n",
    "        2.3 Move along corresponding edge until the next corner is reached <br>\n",
    "\n",
    "\n",
    "<img src=\"img/simplex.png\" height=\"60%\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duality\n",
    "\n",
    "Every LP problem has another special LP problem associated with it. The original problem is named the **primal** whereas the second is called the **dual**.\n",
    "\n",
    "Duality is important:\n",
    "- to determine the optimality of a solution\n",
    "- to determine the sensitivity of a solution to (small) changes of the problem parameters\n",
    "- identifying near-optimal solutions\n",
    "- the dual problem can be used in the convergence analysis of algorithms.\n",
    "\n",
    "\n",
    "### Week and Strong duality\n",
    "\n",
    "Assuming primal and dual to have both feasible solutions:\n",
    "\n",
    "• **Weak duality** (min problem): the cost of any feasible solution of the dual is always less or equal to the cost of any feasible solution of the primal (duality gap). <br>\n",
    "• **Strong duality**: the values of the optimal solutions to the primal and dual are always equal.\n",
    "\n",
    "<br>\n",
    "\n",
    "Any primal solution gives an **upper bound** to the dual.\n",
    "\n",
    "Any dual solution gives a **lower bound** to the primal.\n",
    "\n",
    "Feasible primal cost equal to feasible dual cost is a **certificate of optimality**.\n",
    "\n",
    "\n",
    "### From Primal to Dual\n",
    "\n",
    "<img src=\"img/primal_dual.png\" height=\"60%\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integer linear programming\n",
    "\n",
    "An integer programming problem is a mathematical optimization or feasibility program in which **some or all of the variables are restricted to be integers**.\n",
    "\n",
    "\n",
    "\n",
    "There are three main categories of algorithms for integer\n",
    "programming problems: <br>\n",
    "\n",
    "• **Exact algorithms**: they guarantee to find an optimal solution, but may take an exponential time. They include branch-and-bound, cutting-planes and dynamic programming.\n",
    "\n",
    "• **Approximation algorithms**: they provide in polynomial time a suboptimal solution together with a bound on the quality of the solution proposed.\n",
    "\n",
    "• **Heuristic algorithms**: they provide a suboptimal solution, with no guarantee on its quality. Even the running time is not always guaranteed to be polynomial, but empirical evidence suggests that these algorithms find a good solution fast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch and bound\n",
    "\n",
    "It is a **divide et impera** method. The problem to solve is decomposed into a number of simpler subproblems.\n",
    "Decomposition proceeds recursively until simple sub-sub-problems can be solved.\n",
    "The **overall solution** is derived from the solutions of the subproblems.\n",
    "The decomposition of the problem into subproblems is the **branching phase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
